{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('data/train.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Binning\n",
    "Data binning is a data pre-processing technique used to reduce the effects of minor observation errors. The original data values which fall into a given small interval, a bin, are replaced by a value representative of that interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Age.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = titanic['Age']\n",
    "df = pd.DataFrame(age)\n",
    "\n",
    "cut_labels = ['child', 'teenage', 'young adullt', 'mid-age adult', 'old']\n",
    "cut_bins = [0, 12, 18, 35, 50, 80]\n",
    "\n",
    "df['Age binning'] = pd.cut(df['Age'], bins=cut_bins, labels=cut_labels)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "\n",
    "One hot encoding transforms categorical features to a format that works better with classification and regression algorithms.\n",
    "\n",
    "<img src=\"image/one_hot_encoding.png\"  width=\"400\" />\n",
    "\n",
    "This works very well with most machine learning algorithms. Some algorithms, like random forests, handle categorical values natively. Then, one hot encoding is not necessary. The process of one hot encoding may seem tedious, but fortunately, most modern machine learning libraries can take care of it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = titanic['Pclass']\n",
    "# create dataframe\n",
    "df = pd.DataFrame(cls)\n",
    "\n",
    "one_hot = pd.get_dummies(df['Pclass'], prefix='Pclass').astype(int)\n",
    "df = df.join(one_hot)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "\n",
    "To map data from various distributions to a normal distribution.\n",
    "\n",
    "1. Log transformer\n",
    "2. Box-Cox transformer\n",
    "3. Yeo-Johnson transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('data/OnlineNewsPopularity.csv')\n",
    "news = news[news[' n_tokens_content']>0]\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news[' n_tokens_content'].describe(), news[' n_tokens_content'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "news['log_n_tokens_content'] = np.log10(news[' n_tokens_content'])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2,1,figsize=(4, 5))\n",
    "print(fig)\n",
    "ax1.set_xlabel('Number of Words/Tokens in Article', fontsize=14)\n",
    "ax2.set_xlabel('Log of Number of Words/Tokens', fontsize=14)\n",
    "\n",
    "news[' n_tokens_content'].hist(ax=ax1, bins=20)\n",
    "news['log_n_tokens_content'].hist(ax=ax2, bins=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['log_n_tokens_content'].median(), news['log_n_tokens_content'].mean(), news['log_n_tokens_content'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box-Cox transformer\n",
    "\n",
    "\n",
    "<img src=\"image/boxcox.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "\n",
    "y = news[' n_tokens_content']\n",
    "y, fitted_lambda= boxcox(y, lmbda=None)\n",
    "\n",
    "print(\"lambda :\", fitted_lambda)\n",
    "\n",
    "news['boxcox_n_tokens_content'] = y\n",
    "\n",
    "# plot\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(10, 3))\n",
    "\n",
    "ax1.set_xlabel('Number of Words in Article', fontsize=14)\n",
    "ax2.set_xlabel('Box-cox of Number of Words', fontsize=14)\n",
    "\n",
    "news[' n_tokens_content'].hist(ax=ax1, bins=20)\n",
    "news['boxcox_n_tokens_content'].hist(ax=ax2, bins=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['boxcox_n_tokens_content'].mean(), news['boxcox_n_tokens_content'].median(), news['boxcox_n_tokens_content'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yeo-Johnson transformer\n",
    "source : https://www.stat.umn.edu/arc/yjpower.pdf\n",
    "<img src=\"image/yj.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import yeojohnson\n",
    "\n",
    "y = news[' n_tokens_content']\n",
    "y, lmbda = yeojohnson(y)\n",
    "news['yeojohnson'] = y\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(12, 3))\n",
    "ax1.set_xlabel('Number of Words in Article', fontsize=14)\n",
    "ax2.set_xlabel('yeo-johnson of Number of Words', fontsize=14)\n",
    "news[' n_tokens_content'].hist(ax=ax1, bins=20)\n",
    "news['yeojohnson'].hist(ax=ax2, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['yeojohnson'].mean(), news['yeojohnson'].median(), news['yeojohnson'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling & Normalization\n",
    "Numeric features, such as counts, may increase without bound. Models that are\n",
    "smooth functions of the input, such as linear regression, logistic regression, or\n",
    "anything that involves a matrix, are affected by the scale of the input. Tree-based\n",
    "models, on the other hand, couldn’t care less. If your model is sensitive to the\n",
    "scale of input features, feature scaling could help.\n",
    "\n",
    "\n",
    "1. Min-max\n",
    "2. Standardization\n",
    "3. l2 Norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min-max\n",
    "Min-max scaling squeezes all feature values to be within the range of [0, 1]\n",
    "\n",
    "<img src=\"image/min-max.png\" />\n",
    "\n",
    "Illustration of min-max scaling\n",
    "\n",
    "<img src=\"image/min-max2.png\" width='400'/>\n",
    "\n",
    "\n",
    "#### Standardization\n",
    "\n",
    "It subtracts off the mean of the feature (over all data points) and divides by the\n",
    "variance. Hence, it can also be called **variance scaling**.\n",
    "\n",
    "<img src=\"image/stand.png\" />\n",
    "\n",
    "<img src=\"image/s2.png\" width='400'/>\n",
    "\n",
    "\n",
    "\n",
    "#### L-2 Normalization\n",
    "This technique normalizes (divides) the original feature value by what’s known\n",
    "as the ℓ2 norm, also known as the Euclidean norm.\n",
    "<img src=\"image/l2.png\" width='400'/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.preprocessing as preproc\n",
    "\n",
    "# Look at the original data - the number of words in an article\n",
    "print('values: ',news[' n_tokens_content'].values)\n",
    "# Min-max scaling\n",
    "\n",
    "news['minmax'] = preproc.minmax_scale(news[[' n_tokens_content']])\n",
    "print(\"\\nmin-max : \",news['minmax'].values)\n",
    "\n",
    "# Standardization - note that by definition, some outputs will be negative\n",
    "news['standardized'] = preproc.StandardScaler().fit_transform(news[[' n_tokens_content']])\n",
    "print('\\nstandardized : ',news['standardized'].values)\n",
    "\n",
    "# L2-normalization\n",
    "news['l2_normalized'] = preproc.normalize(news[[' n_tokens_content']], axis=0)\n",
    "print('\\nl2 norm : ',news['l2_normalized'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.minmax.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4,1,figsize=(6,12))\n",
    "fig.tight_layout()\n",
    "\n",
    "news[' n_tokens_content'].hist(ax=ax1, bins=100)\n",
    "ax1.tick_params(labelsize=14)\n",
    "ax1.set_xlabel('Article word count', fontsize=14)\n",
    "ax1.set_ylabel('Number of articles', fontsize=14)\n",
    "\n",
    "news['minmax'].hist(ax=ax2, bins=100)\n",
    "ax2.tick_params(labelsize=14)\n",
    "ax2.set_xlabel('Min-max scaled word count')\n",
    "ax2.set_ylabel('Number of articles', fontsize=14)\n",
    "\n",
    "news['standardized'].hist(ax=ax3, bins=100)\n",
    "ax3.tick_params(labelsize=14)\n",
    "ax3.set_xlabel('Standardized word count')\n",
    "ax3.set_ylabel('Number of articles', fontsize=14)\n",
    "\n",
    "news['l2_normalized'].hist(ax=ax4, bins=100)\n",
    "ax4.tick_params(labelsize=14)\n",
    "ax4.set_xlabel('L2-normalized word count')\n",
    "ax4.set_ylabel('Number of articles', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering With Real-Life Dataset - self study\n",
    "Dataset : https://www.kaggle.com/datasets/patrickgendotti/udacity-course-catalog\n",
    "\n",
    "1. Download and Read data using pandas\n",
    "2. Handle missing values in 'Level', 'Duration', 'Review Count' and 'rating' columns\n",
    "3. Apply one-hot encoding for 'Level' column\n",
    "4. Apply data bining for 'Rating' column\n",
    "5. Apply boxcox transformer for 'Review Count' column and plot the distribution (before and after transformer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
